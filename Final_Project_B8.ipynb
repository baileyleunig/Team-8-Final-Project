{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "507a4fa1",
   "metadata": {},
   "source": [
    "# Final Project - Cloud Platforms - Section B Team 8\n",
    "\n",
    "In this notebook, we predict a Chicago crashes dataset with the XGBoost algorithm. Before running this code, please make sure to create an S3 bucket and a DynamoDB with the primary key \"modelId\". Also be aware that you need to change the name of the S3 bucket and the DynamoDB in the code, and upload the crashes dataset to your S3 bucket. Finally, you need to give SageMaker the permissions to put objects into DynamoDB.  \n",
    "\n",
    "## Environment preparation\n",
    "\n",
    "This section prepares the environment needed for the modeling. \n",
    "\n",
    "### Necessary imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be197a7d",
   "metadata": {},
   "source": [
    "We're importing boto3 and sagemaker because we plan to interact with AWS and use its machine learning services. For our data work, we're including numpy and pandas, which are essential for crunching numbers and handling data frames. Lastly, we've got train_test_split from sklearn, which is crucial for splitting our data into training and test sets, so we can validate our machine learning models effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c12d7ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.10/site-packages (2024.3.1)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /opt/conda/lib/python3.10/site-packages (from s3fs) (2.7.0)\n",
      "Collecting fsspec==2024.3.1 (from s3fs)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from s3fs) (3.9.1)\n",
      "Requirement already satisfied: botocore<1.31.65,>=1.31.16 in /opt/conda/lib/python3.10/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.31.64)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /opt/conda/lib/python3.10/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.16.0)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /opt/conda/lib/python3.10/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (0.11.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (4.0.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.31.65,>=1.31.16->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.31.65,>=1.31.16->aiobotocore<3.0.0,>=2.5.4->s3fs) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.31.65,>=1.31.16->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.26.18)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.31.65,>=1.31.16->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.16.0)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[33mWARNING: Error parsing requirements for fsspec: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/fsspec-2023.6.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: fsspec\n",
      "  Attempting uninstall: fsspec\n",
      "\u001b[33m    WARNING: No metadata found in /opt/conda/lib/python3.10/site-packages\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: fsspec 2023.6.0\n",
      "\u001b[31mERROR: Cannot uninstall fsspec 2023.6.0, RECORD file not found. You might be able to recover from this via: 'pip install --force-reinstall --no-deps fsspec==2023.6.0'.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a96d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "import numpy as np\n",
    "import io\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ee3fe",
   "metadata": {},
   "source": [
    "### Load data & data cleaning\n",
    "\n",
    "Read the data **from a S3 bucket to a CSV**. \n",
    "\n",
    "What we've done here is we've pulled the crash data from an S3 bucket, which is conveniently located in the US West (N. California) region—this choice gives us access to additional features that might be useful for our analysis. We’ve read in the specific columns we need from the CSV file, using pandas. To keep things clean, we’ve converted all column names to lowercase and created a binary 'injuries' column to easily identify records with injuries. We've also transformed the 'date' column into a datetime object, which lets us extract and analyze the data by month, weekday, and hour. After cleaning the data and dropping any rows with missing values, we've applied a filter to only include records with valid latitude readings. This cleaned dataset should give us a solid foundation for our analysis, and it’s all set for any modeling or deeper analysis we want to perform next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0246ecdf-0439-48b9-8c47-0a8b6011d5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posted_speed_limit</th>\n",
       "      <th>first_crash_type</th>\n",
       "      <th>weather_condition</th>\n",
       "      <th>lighting_condition</th>\n",
       "      <th>trafficway_type</th>\n",
       "      <th>roadway_surface_cond</th>\n",
       "      <th>prim_contributory_cause</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>injuries</th>\n",
       "      <th>crash_month</th>\n",
       "      <th>crash_weekday</th>\n",
       "      <th>crash_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>NOT DIVIDED</td>\n",
       "      <td>DRY</td>\n",
       "      <td>UNABLE TO DETERMINE</td>\n",
       "      <td>41.691832</td>\n",
       "      <td>-87.671307</td>\n",
       "      <td>1</td>\n",
       "      <td>November</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>REAR TO SIDE</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DARKNESS, LIGHTED ROAD</td>\n",
       "      <td>FOUR WAY</td>\n",
       "      <td>DRY</td>\n",
       "      <td>FAILING TO YIELD RIGHT-OF-WAY</td>\n",
       "      <td>41.805552</td>\n",
       "      <td>-87.622887</td>\n",
       "      <td>1</td>\n",
       "      <td>November</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>REAR END</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>NOT DIVIDED</td>\n",
       "      <td>DRY</td>\n",
       "      <td>FAILING TO REDUCE SPEED TO AVOID CRASH</td>\n",
       "      <td>41.808378</td>\n",
       "      <td>-87.684571</td>\n",
       "      <td>0</td>\n",
       "      <td>June</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>FIXED OBJECT</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>DIVIDED - W/MEDIAN BARRIER</td>\n",
       "      <td>DRY</td>\n",
       "      <td>UNABLE TO DETERMINE</td>\n",
       "      <td>41.765892</td>\n",
       "      <td>-87.594228</td>\n",
       "      <td>0</td>\n",
       "      <td>May</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>REAR END</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>DARKNESS, LIGHTED ROAD</td>\n",
       "      <td>DIVIDED - W/MEDIAN (NOT RAISED)</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>FAILING TO REDUCE SPEED TO AVOID CRASH</td>\n",
       "      <td>41.692541</td>\n",
       "      <td>-87.618320</td>\n",
       "      <td>0</td>\n",
       "      <td>December</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   posted_speed_limit first_crash_type weather_condition  \\\n",
       "0                  30       PEDESTRIAN             CLEAR   \n",
       "1                  25     REAR TO SIDE             CLEAR   \n",
       "2                  30         REAR END             CLEAR   \n",
       "3                  30     FIXED OBJECT             CLEAR   \n",
       "4                  35         REAR END           UNKNOWN   \n",
       "\n",
       "       lighting_condition                  trafficway_type  \\\n",
       "0                DAYLIGHT                      NOT DIVIDED   \n",
       "1  DARKNESS, LIGHTED ROAD                         FOUR WAY   \n",
       "2                DAYLIGHT                      NOT DIVIDED   \n",
       "3                DAYLIGHT       DIVIDED - W/MEDIAN BARRIER   \n",
       "4  DARKNESS, LIGHTED ROAD  DIVIDED - W/MEDIAN (NOT RAISED)   \n",
       "\n",
       "  roadway_surface_cond                 prim_contributory_cause   latitude  \\\n",
       "0                  DRY                     UNABLE TO DETERMINE  41.691832   \n",
       "1                  DRY           FAILING TO YIELD RIGHT-OF-WAY  41.805552   \n",
       "2                  DRY  FAILING TO REDUCE SPEED TO AVOID CRASH  41.808378   \n",
       "3                  DRY                     UNABLE TO DETERMINE  41.765892   \n",
       "4              UNKNOWN  FAILING TO REDUCE SPEED TO AVOID CRASH  41.692541   \n",
       "\n",
       "   longitude  injuries crash_month crash_weekday  crash_hour  \n",
       "0 -87.671307         1    November     Wednesday          13  \n",
       "1 -87.622887         1    November      Thursday          23  \n",
       "2 -87.684571         0        June        Sunday          13  \n",
       "3 -87.594228         0         May       Tuesday          13  \n",
       "4 -87.618320         0    December       Tuesday          22  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    's3://team-b8/crashes_2022.csv',\n",
    "    usecols=['INJURIES_TOTAL', 'DATE', 'POSTED_SPEED_LIMIT', 'FIRST_CRASH_TYPE', 'WEATHER_CONDITION', 'LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND', 'TRAFFICWAY_TYPE', 'PRIM_CONTRIBUTORY_CAUSE', 'LATITUDE', 'LONGITUDE']\n",
    ")\n",
    "\n",
    "# Change column names to lower case\n",
    "data.columns = data.columns.str.lower()\n",
    "\n",
    "# Create new column called 'injuries' as a prediction target\n",
    "data['injuries'] = np.where(data['injuries_total'] > 0, 1, 0)\n",
    "\n",
    "# Ensure 'date' column is in datetime format for date/time extraction\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Create new columns extracting date/time from 'date' column to analyze data on a more granular level\n",
    "data['crash_month'] = data['date'].dt.month_name()\n",
    "data['crash_weekday'] = data['date'].dt.day_name()\n",
    "data['crash_hour'] = data['date'].dt.hour\n",
    "\n",
    "# Create clean dataset with necessary values\n",
    "crashes_clean = data.drop(['injuries_total', 'date'], axis=1)\n",
    "\n",
    "# Drop rows with any missing values in the selected columns\n",
    "crashes_clean = crashes_clean.dropna()\n",
    "\n",
    "# Additionally, filter rows where latitude > 0\n",
    "crashes_clean = crashes_clean[crashes_clean['latitude'] > 0]\n",
    "\n",
    "crashes_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45b825e1-4fba-48d0-928c-cc9c30094ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107422, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crashes_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55d8e4e-347d-49fe-869b-992dc9593c11",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "We've set up a preprocessing pipeline to get our data ready for machine learning models. First, we separated our target variable, which is whether there were injuries, from the predictors. For numerical data, we created a pipeline to fill any missing values with the mean and then scale the values to have a standard distribution, which helps many models perform better. For the categorical data, we're tackling missing values by substituting them with the most frequent occurrence and then applying one-hot encoding to turn them into a format that our algorithms can work with. We've identified which of our columns are categorical and which are numerical, and we've used a ColumnTransformer to apply the appropriate transformations to each data type. This way, our dataset will be clean, preprocessed, and ready for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12e0ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "# Store prediction target in separate variable\n",
    "X = crashes_clean.drop('injuries', axis=1)\n",
    "y = crashes_clean['injuries']\n",
    "\n",
    "# Define the preprocessing for numerical columns\n",
    "# SimpleImputer to fill missing values with the mean, then scaling the data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define the preprocessing for categorical columns\n",
    "# Filling missing values with the most frequent value then applying one-hot encoding\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "categorical_cols = [\n",
    "    'first_crash_type', 'weather_condition', 'lighting_condition',\n",
    "    'trafficway_type', 'roadway_surface_cond', 'prim_contributory_cause',\n",
    "    'crash_month', 'crash_weekday'\n",
    "]\n",
    "\n",
    "numerical_cols = ['posted_speed_limit', 'latitude', 'longitude', 'crash_hour']\n",
    "\n",
    "# Create the ColumnTransformer with both transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd32f2",
   "metadata": {},
   "source": [
    "### Train / val / test split & data preprocessing\n",
    "\n",
    "We've divided our dataset into separate training, validation, and test sets to ensure we can train our models effectively and evaluate their performance accurately. We allocated 80% of the data for training and then split the remaining 20% equally for validation and testing. This helps us to tune the model parameters using the validation set without touching the test set, which is reserved for the final performance check.\n",
    "\n",
    "Once our data was split, we applied our preprocessing steps to each set. We fitted the preprocessor to the training data, which means it learned what transformations to apply from this data, such as the mean for imputing missing values and the scaling parameters. Then, we transformed the training set with these fitted parameters. The validation and test sets were only transformed, not fitted, to mimic the real-world scenario where the model is applied to new, unseen data. This process is crucial for avoiding data leakage and ensuring that our model's performance metrics are genuine and reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5bfc6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation, and test sets\n",
    "X_train, X_testval, y_train, y_testval = train_test_split(X, y, train_size=0.8, random_state=1200)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_testval, y_testval, train_size=0.5, random_state=1200)\n",
    "\n",
    "# Apply preprocessing to the training, validation, and test sets\n",
    "# Fit and transform the training set\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "# Transform the validation and test set\n",
    "X_val_preprocessed = preprocessor.transform(X_val)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9156cf6-b0e3-4604-bbf8-a6f76de00c1c",
   "metadata": {},
   "source": [
    "### Transform preprocessed data\n",
    "\n",
    "We've reached the stage where we're stitching everything back together after preprocessing. Our numerical features kept their names, which keeps things straightforward for us. But for our categorical features, since they went through one-hot encoding, they got new names based on their unique values, so we fetched these new names from our preprocessor.\n",
    "\n",
    "With all of our feature names in hand, we combined them to keep track of our columns post-transformation. Because our preprocessing resulted in sparse matrices—efficient for storage when dealing with a lot of zeros—we used hstack to horizontally stack our target variable, y, back with our transformed features, X. Now, our training, validation, and test sets are back in a complete form, with rows representing records and columns representing features, ready for the learning stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b427ce5-f705-47aa-8137-a6e97af44ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Get the feature names since they were removed through the preprocessing\n",
    "# For the numerical features, the names stay the same\n",
    "numerical_features = numerical_cols\n",
    "\n",
    "# For the categorical features, get the new column names from the one-hot encoder\n",
    "categorical_features = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Combine the feature names from both transformations\n",
    "all_features = list(numerical_features) + list(categorical_features)\n",
    "\n",
    "# Recombine X and y for each set, taking into account that X_*_preprocessed are sparse matrices\n",
    "train_preprocessed = hstack([y_train.values.reshape(-1, 1), X_train_preprocessed])\n",
    "val_preprocessed = hstack([y_val.values.reshape(-1, 1), X_val_preprocessed])\n",
    "test_preprocessed = hstack([y_test.values.reshape(-1, 1), X_test_preprocessed])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3017bb33-e624-4915-85ef-97ed3ca14e17",
   "metadata": {},
   "source": [
    "### View preprocessed data\n",
    "\n",
    "To take a closer look and make it more human-readable, we're converting it into Compressed Sparse Row (CSR) format. This format is particularly good for quick row operations, which is exactly what we need.\n",
    "\n",
    "Next, we're grabbing the first five rows of this CSR matrix and converting them to a dense format, meaning we're turning it back into a regular array with all the values filled in. This makes it possible to actually see the data instead of just the structure and non-zero entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26c62119-57c1-4d33-af3f-3ff521a16f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>injuries</th>\n",
       "      <th>posted_speed_limit</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>crash_hour</th>\n",
       "      <th>first_crash_type_ANGLE</th>\n",
       "      <th>first_crash_type_ANIMAL</th>\n",
       "      <th>first_crash_type_FIXED OBJECT</th>\n",
       "      <th>first_crash_type_HEAD ON</th>\n",
       "      <th>first_crash_type_OTHER NONCOLLISION</th>\n",
       "      <th>...</th>\n",
       "      <th>crash_month_November</th>\n",
       "      <th>crash_month_October</th>\n",
       "      <th>crash_month_September</th>\n",
       "      <th>crash_weekday_Friday</th>\n",
       "      <th>crash_weekday_Monday</th>\n",
       "      <th>crash_weekday_Saturday</th>\n",
       "      <th>crash_weekday_Sunday</th>\n",
       "      <th>crash_weekday_Thursday</th>\n",
       "      <th>crash_weekday_Tuesday</th>\n",
       "      <th>crash_weekday_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252922</td>\n",
       "      <td>0.627758</td>\n",
       "      <td>0.408668</td>\n",
       "      <td>-0.251554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.630523</td>\n",
       "      <td>-1.030480</td>\n",
       "      <td>0.552135</td>\n",
       "      <td>-0.982718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252922</td>\n",
       "      <td>0.015424</td>\n",
       "      <td>-0.960258</td>\n",
       "      <td>-0.068763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.136367</td>\n",
       "      <td>-1.638799</td>\n",
       "      <td>0.610990</td>\n",
       "      <td>1.210774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252922</td>\n",
       "      <td>0.200728</td>\n",
       "      <td>0.925505</td>\n",
       "      <td>0.662401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   injuries  posted_speed_limit  latitude  longitude  crash_hour  \\\n",
       "0       0.0            0.252922  0.627758   0.408668   -0.251554   \n",
       "1       0.0           -0.630523 -1.030480   0.552135   -0.982718   \n",
       "2       0.0            0.252922  0.015424  -0.960258   -0.068763   \n",
       "3       0.0            1.136367 -1.638799   0.610990    1.210774   \n",
       "4       0.0            0.252922  0.200728   0.925505    0.662401   \n",
       "\n",
       "   first_crash_type_ANGLE  first_crash_type_ANIMAL  \\\n",
       "0                     0.0                      0.0   \n",
       "1                     0.0                      0.0   \n",
       "2                     0.0                      0.0   \n",
       "3                     0.0                      0.0   \n",
       "4                     0.0                      0.0   \n",
       "\n",
       "   first_crash_type_FIXED OBJECT  first_crash_type_HEAD ON  \\\n",
       "0                            0.0                       0.0   \n",
       "1                            0.0                       0.0   \n",
       "2                            0.0                       0.0   \n",
       "3                            0.0                       0.0   \n",
       "4                            0.0                       0.0   \n",
       "\n",
       "   first_crash_type_OTHER NONCOLLISION  ...  crash_month_November  \\\n",
       "0                                  0.0  ...                   0.0   \n",
       "1                                  0.0  ...                   0.0   \n",
       "2                                  0.0  ...                   0.0   \n",
       "3                                  0.0  ...                   0.0   \n",
       "4                                  0.0  ...                   1.0   \n",
       "\n",
       "   crash_month_October  crash_month_September  crash_weekday_Friday  \\\n",
       "0                  0.0                    0.0                   0.0   \n",
       "1                  0.0                    0.0                   0.0   \n",
       "2                  1.0                    0.0                   0.0   \n",
       "3                  1.0                    0.0                   0.0   \n",
       "4                  0.0                    0.0                   0.0   \n",
       "\n",
       "   crash_weekday_Monday  crash_weekday_Saturday  crash_weekday_Sunday  \\\n",
       "0                   0.0                     0.0                   1.0   \n",
       "1                   0.0                     0.0                   0.0   \n",
       "2                   0.0                     0.0                   0.0   \n",
       "3                   0.0                     0.0                   0.0   \n",
       "4                   0.0                     0.0                   1.0   \n",
       "\n",
       "   crash_weekday_Thursday  crash_weekday_Tuesday  crash_weekday_Wednesday  \n",
       "0                     0.0                    0.0                      0.0  \n",
       "1                     0.0                    0.0                      1.0  \n",
       "2                     1.0                    0.0                      0.0  \n",
       "3                     0.0                    1.0                      0.0  \n",
       "4                     0.0                    0.0                      0.0  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "# Convert matrix to CSR first for efficient row slicing\n",
    "train_preprocessed_csr = csr_matrix(train_preprocessed)\n",
    "\n",
    "# Slice the first 5 rows and convert them to dense format\n",
    "train_preprocessed_head_dense = train_preprocessed_csr[:5].toarray()\n",
    "\n",
    "# Create a DataFrame with the proper column names for the head of the dataset\n",
    "train_preprocessed_head_df = pd.DataFrame(train_preprocessed_head_dense, columns=['injuries'] + all_features)\n",
    "\n",
    "# Display the head of the DataFrame\n",
    "train_preprocessed_head_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba1f7b3",
   "metadata": {},
   "source": [
    "### Define S3 upload function\n",
    "\n",
    "We've crafted a function to handle the upload of our processed data back to S3. This function, upload_to_s3, first transforms the sparse matrix into a dense array, then into a pandas DataFrame, which we then write to a CSV format without any headers or index. We use an in-memory buffer, io.StringIO, for this, so we're not writing files to disk—neat and fast. After converting the data into a CSV string within the buffer, we simply upload this string to the specified S3 bucket and file path. By doing this, we're making sure that our preprocessed training and validation data are safely stored in the cloud, which is especially useful if we want to access this data again later or share it with others for further analysis or replication of our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1af200a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "def upload_to_s3(matrix, bucket, filename):\n",
    "    # Convert the sparse matrix to a dense format (numpy array), then to a DataFrame\n",
    "    df = pd.DataFrame(matrix.toarray())\n",
    "    placeholder = io.StringIO()\n",
    "    df.to_csv(placeholder, header=False, index=False)\n",
    "    # Upload csv string to S3\n",
    "    object = s3.Object(bucket, filename)\n",
    "    object.put(Body=placeholder.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d64d4fc",
   "metadata": {},
   "source": [
    "After defining this, the train and validation split are uploaded to the S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30701f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_to_s3(train_preprocessed, 'team-b8', 'sagemaker-data/kc/train.csv')\n",
    "upload_to_s3(val_preprocessed, 'team-b8', 'sagemaker-data/kc/val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66910419",
   "metadata": {},
   "source": [
    "## Setting up the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c5ac5",
   "metadata": {},
   "source": [
    "We're utilizing the `Estimator` class from the `sagemaker.estimator` module, which essentially sets up a virtual environment for us to train our models on AWS without fussing over the details. Think of it like renting a lab equipped with all the gadgets we need for our experiments.\n",
    "\n",
    "As for the model evaluation parameters, they're our yardsticks for performance. The AUC, or Area Under the Curve, tells us about the model's ability to classify between our classes—injuries or no injuries. A perfect model would have an AUC of 1, but we'll likely see a number less than that.\n",
    "\n",
    "Logloss, or Logarithmic Loss, measures the accuracy of our classifier by penalizing false classifications. Lower logloss values mean better predictions, so we're aiming for as low as possible.\n",
    "\n",
    "Lastly, we have the Error, which is simply the proportion of times our model predicts incorrectly. It's one minus the accuracy, so if our model was right 80% of the time, the error would be 20%. We're tracking these metrics to refine our model until it's as accurate as it can be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d56285",
   "metadata": {},
   "source": [
    "We’ve configured the SageMaker Estimator with the necessary settings to train our model. This involves setting up an environment with XGBoost, specifying where to save our outputs in S3, and what metrics to use for evaluating model performance. We've then prepared the data channels, telling SageMaker where to find our training and validation data in S3, all formatted as CSV for convenience. With this in place, our model is ready to start learning from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "158fbed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "region_name = boto3.Session().region_name\n",
    "container = sagemaker.image_uris.retrieve('xgboost', region_name, version='0.90-1')\n",
    "output_location = 's3://team-b8/sagemaker-output/'\n",
    "\n",
    "hyperparams = {\n",
    "    'eval_metric': 'auc,logloss,error',\n",
    "    'num_round': '20',\n",
    "    'objective': 'binary:logistic'\n",
    "}\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    output_path=output_location,\n",
    "    hyperparameters=hyperparams,\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8722b5c6",
   "metadata": {},
   "source": [
    "Now we create \"channels\". We need to specify where is the data and in which format in a specific dictionary:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e5c0f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "train_channel = sagemaker.session.s3_input(\n",
    "    's3://team-b8/sagemaker-data/kc/train.csv',\n",
    "    content_type='text/csv'\n",
    ")\n",
    "val_channel = sagemaker.session.s3_input(\n",
    "    's3://team-b8/sagemaker-data/kc/val.csv',\n",
    "    content_type='text/csv'\n",
    ")\n",
    "\n",
    "channels_for_training = {\n",
    "    'train': train_channel,\n",
    "    'validation': val_channel\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937e5471",
   "metadata": {},
   "source": [
    "### Train first model (XGBoost)\n",
    "\n",
    "We've just kicked off the training of our first model using XGBoost. With the estimator.fit command, SageMaker starts the training job, pulling in the data from the channels we set up. The logs are turned off for a cleaner output, but we can see from the info message that our training job is up and running. It goes through steps like starting up, preparing the instances, downloading the data, and finally running the training process. Once it's done training, it uploads the model artifacts back to S3. This sequence of steps is all standard for model training in SageMaker, and it's nice to see it all executing smoothly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d0087c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2024-04-02-17-27-04-355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-04-02 17:27:05 Starting - Starting the training job..\n",
      "2024-04-02 17:27:20 Starting - Preparing the instances for training..........\n",
      "2024-04-02 17:28:17 Downloading - Downloading input data.......\n",
      "2024-04-02 17:28:57 Downloading - Downloading the training image....\n",
      "2024-04-02 17:29:22 Training - Training image download completed. Training in progress.....\n",
      "2024-04-02 17:29:47 Uploading - Uploading generated training model..\n",
      "2024-04-02 17:30:04 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs=channels_for_training, logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f92cbd-908e-4482-8b87-33da5f1c6d35",
   "metadata": {},
   "source": [
    "### Retrieve metrics of the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "097aea4c-75c8-4be6-936c-aecf6d593830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>train:auc</td>\n",
       "      <td>0.786952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>validation:auc</td>\n",
       "      <td>0.769895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>train:logloss</td>\n",
       "      <td>0.390760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>validation:logloss</td>\n",
       "      <td>0.393552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>train:error</td>\n",
       "      <td>0.122934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>validation:error</td>\n",
       "      <td>0.121160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp         metric_name     value\n",
       "0        0.0           train:auc  0.786952\n",
       "1        0.0      validation:auc  0.769895\n",
       "2        0.0       train:logloss  0.390760\n",
       "3        0.0  validation:logloss  0.393552\n",
       "4        0.0         train:error  0.122934\n",
       "5        0.0    validation:error  0.121160"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get metrics of initial model\n",
    "metrics = sagemaker.analytics.TrainingJobAnalytics(\n",
    "    estimator._current_job_name,\n",
    "    metric_names=['train:auc', 'validation:auc', 'train:logloss', 'validation:logloss', 'train:error', 'validation:error']\n",
    ")\n",
    "metrics.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db45b229-36e6-4258-a143-e3bffbbca7af",
   "metadata": {},
   "source": [
    "### Interpretation of metrics\n",
    "\n",
    "After our model finished training, we pulled the performance metrics to see how well it did. The training AUC of about 0.78 suggests our model is doing a pretty good job at distinguishing between classes—a higher score would be even better, but this is a solid start. The validation AUC is close to the training AUC, which is good because it means our model isn’t just memorizing the training data; it’s generalizing well to unseen data.\n",
    "\n",
    "The log loss for both training and validation is around 0.39. Since log loss measures prediction error, a lower number is better, and this shows our model's predictions are reasonably well-calibrated.\n",
    "\n",
    "Lastly, the error rate sits at around 0.12 for both training and validation, implying an accuracy of about 88%. This is a strong indicator that our model is making the right calls most of the time when predicting whether there were injuries in the crashes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d6f8e3-03b6-42bd-94ce-f2c1913cd9ad",
   "metadata": {},
   "source": [
    "## Model tuning\n",
    "\n",
    "We're fine-tuning our model's hyperparameters using SageMaker's tuning job. We've defined ranges for each parameter and set our model to focus on improving the AUC on the validation set. With early stopping after 10 rounds to prevent overfitting, the job will test up to 30 different settings to find the best ones. This systematic search is all about boosting the model's ability to predict accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed60d885-b560-4b5a-8a5c-240b0b0d2b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating hyperparameter tuning job with name: sagemaker-xgboost-240402-1741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "# Specify the hyperparameter ranges\n",
    "hyperparameter_ranges = {\n",
    "    'eta': ContinuousParameter(0.01, 0.2),\n",
    "    'min_child_weight': ContinuousParameter(1, 10),\n",
    "    'alpha': ContinuousParameter(0, 2),\n",
    "    'max_depth': IntegerParameter(3, 10),\n",
    "    'subsample': ContinuousParameter(0.5, 1),\n",
    "    'colsample_bytree': ContinuousParameter(0.5, 1),\n",
    "    'gamma': ContinuousParameter(0, 5),\n",
    "    'lambda': ContinuousParameter(1e-5, 10),\n",
    "}\n",
    "\n",
    "# Modify estimator\n",
    "estimator.set_hyperparameters(\n",
    "    eval_metric='auc,logloss,error',\n",
    "    num_round=1000,  # Set a large number for num_round and rely on early stopping\n",
    "    objective='binary:logistic',\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "# Save tuning jobs in different path\n",
    "estimator.output_path = 's3://team-b8/sagemaker-output/hyperparameter-tuning/'\n",
    "\n",
    "# Specify the objective metric\n",
    "objective_metric = 'validation:auc'\n",
    "\n",
    "# Create and launch a hyperparameter tuning job\n",
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=30,\n",
    "                            max_parallel_jobs=10)\n",
    "\n",
    "# Specify the training and validation data locations and content type\n",
    "train_input = TrainingInput('s3://team-b8/sagemaker-data/kc/train.csv', content_type='text/csv')\n",
    "validation_input = TrainingInput('s3://team-b8/sagemaker-data/kc/val.csv', content_type='text/csv')\n",
    "\n",
    "# Launch a hyperparameter tuning job\n",
    "tuner.fit({'train': train_input, 'validation': validation_input}, logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4302dc8b",
   "metadata": {},
   "source": [
    "### Retrieve metrics of model tuning\n",
    "\n",
    "We've used SageMaker's session to retrieve the details of our best training job post-tuning. It's like we've held a contest for our models, and now we're meeting the winner. We fetched the winning hyperparameters and printed them out to see what made this model stand out. With these optimal settings in hand, we looked at the key performance metrics: AUC, log loss, and error on the validation set. Printing these metrics gave us insight into just how well this model is expected to perform when making predictions. It's a moment of truth, seeing if our tuning efforts have paid off in creating a more accurate and reliable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50cd08e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "The best hyperparameters are: \n",
      " {'_tuning_objective_metric': 'validation:auc', 'alpha': '1.4071495043371078', 'colsample_bytree': '0.5436108896616062', 'early_stopping_rounds': '10', 'eta': '0.1059320330255047', 'eval_metric': 'auc,logloss,error', 'gamma': '1.7373337310860146', 'lambda': '0.03994046436954013', 'max_depth': '6', 'min_child_weight': '1.0', 'num_round': '1000', 'objective': 'binary:logistic', 'subsample': '0.6203075396151405'}\n",
      "\n",
      "The following metrics are from the best model:\n",
      "validation:logloss: 0.32312801480293274\n",
      "validation:auc: 0.7994499802589417\n",
      "validation:error: 0.11878599971532822\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get the name of the best training job from hyperparameter tuning\n",
    "best_training_job_name = tuner.best_training_job()\n",
    "\n",
    "# Now get the details of the best training job\n",
    "best_training_job_info = sagemaker_session.describe_training_job(best_training_job_name)\n",
    "\n",
    "# The hyperparameters of the best training job are in the 'HyperParameters' key\n",
    "best_hyperparameters = best_training_job_info['HyperParameters']\n",
    "\n",
    "print(f\"The best hyperparameters are: \\n {best_hyperparameters}\")\n",
    "\n",
    "# Describe the best training job to get the metrics\n",
    "metrics = best_training_job_info['FinalMetricDataList']\n",
    "\n",
    "print(\"\\nThe following metrics are from the best model:\")\n",
    "# Print out the metrics for the best training job\n",
    "for metric in metrics:\n",
    "    if metric['MetricName'] in ['validation:auc', 'validation:logloss', 'validation:error']:\n",
    "        print(f\"{metric['MetricName']}: {metric['Value']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cd15b6-201d-4e9e-83f3-2806ea8f2f1c",
   "metadata": {},
   "source": [
    "### Interpretation of metrics\n",
    "\n",
    "The metrics from the best model after hyperparameter tuning tell us a promising story. We have a validation AUC of almost 0.80, indicating strong predictive power and the model's good ability to distinguish between the positive and negative classes. This is a key metric for classification problems, and being close to 1 is what we aim for.\n",
    "\n",
    "The validation log loss at around 0.32 suggests our predictions are quite confident and generally accurate, as this metric punishes both confident wrong predictions and unconfident right ones.\n",
    "\n",
    "A validation error of roughly 0.118—or about 11.8%—translates to an accuracy of approximately 88.2%. This means that our model correctly predicts whether there were injuries in a crash 88.2% of the time, which is quite effective for many practical applications.\n",
    "\n",
    "The chosen hyperparameters that led to these metrics show a particular configuration of the model complexity, regularization, and the learning process. For instance, a 'max_depth' of 6 and 'min_child_weight' of approximately 1.0 suggest a certain level of complexity that the model can capture, while regularization parameters like 'alpha', 'lambda', and 'gamma' help prevent overfitting. The 'eta' value shows a moderate learning rate, and 'subsample' indicates a portion of the data used to grow trees, preventing overfitting as well.\n",
    "\n",
    "All in all, these results suggest a well-tuned model that balances bias and variance to make reliable predictions on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedae8e4-6771-419c-89e0-deb1b6213613",
   "metadata": {},
   "source": [
    "### Trial of retrieving feature importance\n",
    "\n",
    "In our machine learning process, we attempted to extract feature importance from our trained model using AWS SageMaker. Despite correctly accessing the model artifacts from the S3 bucket and employing the XGBoost library, the Jupyter notebook environment consistently crashed upon execution of the loading code.\n",
    "\n",
    "We have taken several measures to address this, such as checking for memory issues and ensuring XGBoost compatibility, yet the problem persists. For the time being, this technical hiccup has halted our ability to directly obtain feature importance. We plan to investigate this as next steps and find a resolution.\n",
    "\n",
    "Below is the code we used in this attempt, documented for transparency and future troubleshooting efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "620b2af7-8a25-44c5-be21-b1d0357ed409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tarfile\n",
    "# import xgboost as xgb\n",
    "# import os\n",
    "\n",
    "# s3_client = boto3.client('s3')\n",
    "\n",
    "# Extract the S3 path where the model artifacts are stored\n",
    "# model_artifacts_s3_path = best_training_job_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "# path_parts = model_artifacts_s3_path.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "# bucket_name = path_parts[0]\n",
    "# object_key = path_parts[1]\n",
    "\n",
    "# Fetch the model artifacts file from S3\n",
    "# response = s3_client.get_object(Bucket=bucket_name, Key=object_key)\n",
    "\n",
    "# Read the file content into memory\n",
    "# file_content = response['Body'].read()\n",
    "\n",
    "# Specify a path in the SageMaker local file system\n",
    "# local_model_dir = \"/home/ec2-user/SageMaker/model-artifacts\"\n",
    "# os.makedirs(local_model_dir, exist_ok=True)\n",
    "\n",
    "# Load the tar.gz file into a TarFile object\n",
    "# model_file_name = 'xgboost-model'\n",
    "# with tarfile.open(fileobj=io.BytesIO(file_content), mode=\"r:gz\") as tar:\n",
    "    # Try to extract the file with the known name 'xgboost-model'\n",
    "    #try:\n",
    "        # Extract the model file to the disk\n",
    "        # tar.extract(model_file_name, path=local_model_dir)\n",
    "    # except KeyError:\n",
    "        # The file wasn't found in the archive, handle the exception as needed\n",
    "        # print(f\"The file {model_file_name} does not exist in the archive.\")\n",
    "        # raise\n",
    "        \n",
    "# model = xgb.Booster()\n",
    "# model_path = os.path.join(local_model_dir, model_file_name)  # This is the file path to the model\n",
    "# model.load_model(model_path)\n",
    "\n",
    "# Extract feature importance\n",
    "# feature_importance = model.get_score(importance_type='weight')\n",
    "# print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88646c78-8026-47ab-9e6c-60409586ec42",
   "metadata": {},
   "source": [
    "### Add information of best model to DynamoDB\n",
    "\n",
    "In the following, the details of the best model (from hyperparameter tuning) are saved in a table inside the DynamoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05be808d-b12c-4879-b384-6b01224ec946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Initialize a DynamoDB client\n",
    "dynamodb = boto3.client('dynamodb')\n",
    "\n",
    "# Define the DynamoDB table name\n",
    "table_name = 'BestModels_FinalAssignment'\n",
    "\n",
    "desired_metrics = {}\n",
    "desired_metric_names = ['validation:logloss', 'validation:auc', 'validation:error']\n",
    "for metric in metrics:\n",
    "    if metric['MetricName'] in desired_metric_names:\n",
    "        desired_metrics[metric['MetricName']] = metric['Value']\n",
    "\n",
    "# Convert hyperparameters and metrics to JSON strings\n",
    "hyperparameters_json = json.dumps(best_hyperparameters)\n",
    "metrics_json = json.dumps(desired_metrics)\n",
    "\n",
    "# Insert the item into the DynamoDB table\n",
    "response = dynamodb.put_item(\n",
    "    TableName=table_name,\n",
    "    Item={\n",
    "        'modelId': {'S': best_training_job_name},\n",
    "        'hyperparameters': {'S': hyperparameters_json},\n",
    "        'metrics': {'S': metrics_json}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd7a72d",
   "metadata": {},
   "source": [
    "## Deploying the model\n",
    "\n",
    "Now that the model is ready, we can \"deploy it\". This will create an instance that \"serves\" the model continuosuly. This server will accept queries with input values in real time and will return the model prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "870f45c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "\n",
      "2024-04-02 17:47:32 Starting - Found matching resource for reuse\n",
      "2024-04-02 17:47:32 Downloading - Downloading the training image\n",
      "2024-04-02 17:47:32 Training - Training image download completed. Training in progress.\n",
      "2024-04-02 17:47:32 Uploading - Uploading generated training model\n",
      "2024-04-02 17:47:32 Completed - Resource released due to keep alive period expiry"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2024-04-02-18-23-50-567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-xgboost-2024-04-02-18-23-50-567\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-xgboost-2024-04-02-18-23-50-567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "# Create a new estimator object from the best training job\n",
    "best_estimator = sagemaker.estimator.Estimator.attach(best_training_job_name)\n",
    "\n",
    "# Now, deploy the best model\n",
    "predictor = best_estimator.deploy(initial_instance_count=1,\n",
    "                                  instance_type='ml.m4.xlarge',\n",
    "                                  serializer=sagemaker.serializers.CSVSerializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9012956",
   "metadata": {},
   "source": [
    "### Predict data\n",
    "\n",
    "We're on to predicting with our model, starting by carving out a small, manageable piece of the test data—the first five rows—to keep things simple. We've got a peek at the subset to ensure it looks correct before it hits the preprocessing pipeline, where it's scaled and encoded just like we did with the training data.\n",
    "\n",
    "The preprocessed data is then converted from a sparse matrix to a dense format, necessary for making predictions. We put this into a pandas DataFrame, making it look like a neat table, and then output it to a CSV string, because that's what our model is trained to digest. Now, with our data neatly packaged, our model is ready to make some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b080534-29e0-4e0c-92cd-c98e2ed48644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset of X_test before preprocessing:\n",
      "       posted_speed_limit          first_crash_type weather_condition  \\\n",
      "67127                  30                  REAR END             CLEAR   \n",
      "51878                  30      PARKED MOTOR VEHICLE              RAIN   \n",
      "77924                  30  SIDESWIPE SAME DIRECTION             CLEAR   \n",
      "36507                  30  SIDESWIPE SAME DIRECTION             CLEAR   \n",
      "57305                  25                     ANGLE             CLEAR   \n",
      "\n",
      "           lighting_condition                  trafficway_type  \\\n",
      "67127                DAYLIGHT                      NOT DIVIDED   \n",
      "51878  DARKNESS, LIGHTED ROAD                      NOT DIVIDED   \n",
      "77924                DAYLIGHT  DIVIDED - W/MEDIAN (NOT RAISED)   \n",
      "36507                DAYLIGHT  DIVIDED - W/MEDIAN (NOT RAISED)   \n",
      "57305                DAYLIGHT                         FOUR WAY   \n",
      "\n",
      "      roadway_surface_cond      prim_contributory_cause   latitude  longitude  \\\n",
      "67127                  DRY        FOLLOWING TOO CLOSELY  41.867065 -87.659250   \n",
      "51878                  WET                      WEATHER  41.999341 -87.660523   \n",
      "77924                  DRY  IMPROPER OVERTAKING/PASSING  41.903503 -87.650005   \n",
      "36507                  DRY          IMPROPER LANE USAGE  41.867453 -87.632334   \n",
      "57305                  DRY          UNABLE TO DETERMINE  41.800311 -87.739432   \n",
      "\n",
      "      crash_month crash_weekday  crash_hour  \n",
      "67127    February        Friday          14  \n",
      "51878   September        Sunday          21  \n",
      "77924       March        Sunday          11  \n",
      "36507       April     Wednesday          11  \n",
      "57305     January      Thursday          13  \n"
     ]
    }
   ],
   "source": [
    "# Create subset of X_test to predict\n",
    "subset_X_test = X_test.iloc[:5]\n",
    "\n",
    "# Display the subset of X_test with column names\n",
    "print(\"Subset of X_test before preprocessing:\")\n",
    "print(subset_X_test)\n",
    "\n",
    "# Preprocess the subset\n",
    "subset_X_test_preprocessed = preprocessor.transform(subset_X_test)\n",
    "\n",
    "# Convert the preprocessed subset to a dense format if it's sparse\n",
    "subset_X_test_preprocessed_dense = subset_X_test_preprocessed.toarray()\n",
    "\n",
    "# Create a DataFrame for the preprocessed data\n",
    "subset_X_test_preprocessed_df = pd.DataFrame(subset_X_test_preprocessed_dense)\n",
    "\n",
    "# Convert the preprocessed DataFrame to CSV format for prediction\n",
    "placeholder = io.StringIO()\n",
    "subset_X_test_preprocessed_df.to_csv(placeholder, header=False, index=False)\n",
    "csv_data = placeholder.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e4b297a-2b5c-411a-9b73-c0d33385ed84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'0.08622758835554123,0.09884343296289444,0.03943060711026192,0.057139601558446884,0.2054167538881302'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict data with deployed model endpoint\n",
    "predictions = predictor.predict(csv_data)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d31b80-2b51-4334-bdf9-e8956cf39e2e",
   "metadata": {},
   "source": [
    "### Interpretation of results\n",
    "\n",
    "The output shows the predictions from our deployed model. Each number is the model's estimated probability of the positive class—in this case, the likelihood of injuries occurring in a crash. The values range from about 0.04 to 0.21, which suggests varying levels of risk across the different instances in our test subset. The closer the value is to 1, the higher the model assesses the risk of injury. For instance, the third prediction at approximately 0.04 indicates a lower probability of injuries compared to the last prediction, which is nearly 0.20. These results would help us identify instances with higher risks that may require further attention or intervention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4708d1-9c46-4f61-9df1-55dd1246ab1d",
   "metadata": {},
   "source": [
    "### Confusion matrix & generalization scores\n",
    "\n",
    "We've put our model's predictions to the test, transforming the probabilities into binary outcomes to calculate a confusion matrix and key performance metrics. The accuracy tells us how often the model is right, precision and recall show us the quality of its positive predictions and its ability to capture the actual positives, respectively. The F1 score helps us balance precision and recall, and the ROC AUC score gauges the model’s ability to distinguish between classes. These metrics give us a well-rounded view of our model's effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ae877f4-a134-4df1-8b4e-b4052399a52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8795\n",
      "Precision: 0.7967\n",
      "Recall: 0.2430\n",
      "F1 Score: 0.3725\n",
      "ROC AUC Score: 0.8059\n",
      "Confusion Matrix:\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                9065                  98\n",
      "Actual Positive                1196                 384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Use preprocessed test set (without prediction target) from the beginning and convert sparse matrix to dense array\n",
    "X_test_dense = X_test_preprocessed.toarray() \n",
    "\n",
    "# Create a DataFrame from the dense array\n",
    "X_test_preprocessed_df = pd.DataFrame(X_test_dense)\n",
    "\n",
    "# Convert to CSV format and predict\n",
    "predictions = predictor.predict(X_test_preprocessed_df.to_csv(header=False, index=False)).decode('utf-8')\n",
    "predicted_probabilities = np.fromstring(predictions, sep=',')\n",
    "predicted_labels = (predicted_probabilities >= 0.5).astype(int)\n",
    "\n",
    "# Calculate the confusion matrix with prediction target of test set\n",
    "cm = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "cm_labeled = pd.DataFrame(cm, \n",
    "                     index=['Actual Negative', 'Actual Positive'], \n",
    "                     columns=['Predicted Negative', 'Predicted Positive'])\n",
    "\n",
    "# Compute various performance metrics\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "precision = precision_score(y_test, predicted_labels)\n",
    "recall = recall_score(y_test, predicted_labels)\n",
    "f1 = f1_score(y_test, predicted_labels)\n",
    "roc_auc = roc_auc_score(y_test, predicted_probabilities)  # Use predicted probabilities for ROC AUC\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Additionally, print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbb2383-340b-4d89-ac9e-e412505bb70b",
   "metadata": {},
   "source": [
    "### Interpretation of results\n",
    "\n",
    "These results paint a detailed picture of our model's performance. With an accuracy of 87.95%, our model is correctly predicting a large majority of the outcomes. However, the precision of 79.67% indicates that when the model predicts an injury, it's correct about 79% of the time. \n",
    "\n",
    "The recall, at 24.30%, is relatively low, suggesting that the model is only identifying about a quarter of all actual injury cases. This could imply that while our model is conservative in predicting injuries, it's missing quite a few that do occur.\n",
    "\n",
    "The F1 score, which combines precision and recall into a single number, is 37.25%, reflecting that there's a significant imbalance between precision and recall. This could be due to a model that is very cautious about predicting an injury, thereby missing out on many true injury cases.\n",
    "\n",
    "The ROC AUC score is 80.59%, a strong score that tells us the model is quite good at ranking predictions correctly, despite the low recall.\n",
    "\n",
    "The confusion matrix gives us a breakdown of the actual predictions: 9065 true negatives and 384 true positives show correct predictions, while there are 98 false positives and 1196 false negatives. This confirms that our model is more likely to predict 'no injury' when in doubt, leading to a high number of false negatives and thus the low recall.\n",
    "\n",
    "Overall, while the model is generally accurate, it is particularly cautious, leading to many missed injury cases. Depending on the application, this could be an area to improve, especially if the cost of missing true injury cases is high."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
